{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from src.movientities.models.char_lstm import CharBilstm\n",
    "from src.movientities.utils.processors import NerPreProcessor\n",
    "from src.movientities.char_bilstm_trainer import CharBilstmTrainer\n",
    "from src.movientities.data.build_dataset import CharCorpus, BuildData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 7816 sentences\n",
      "Test set: 1953 sentences\n"
     ]
    }
   ],
   "source": [
    "dataset = CharCorpus(\n",
    "    input_folder=f\"/home/kemalaraz/Desktop/MovieEntityRecognizer/data/modified/trivia_tab_format\",\n",
    "    min_word_freq=3,\n",
    "    batch_size=64,\n",
    ")\n",
    "print(f\"Train set: {len(dataset.train_dataset)} sentences\")\n",
    "print(f\"Test set: {len(dataset.test_dataset)} sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 1,714,249 trainable parameters.\n",
      "CharBilstm(\n",
      "  (embedding): Embedding(4529, 300, padding_idx=1)\n",
      "  (emb_dropout): Dropout(p=0.5, inplace=False)\n",
      "  (char_emb): Embedding(39, 25, padding_idx=1)\n",
      "  (char_cnn): Conv1d(25, 125, kernel_size=(3,), stride=(1,), groups=25)\n",
      "  (cnn_dropout): Dropout(p=0.25, inplace=False)\n",
      "  (lstm): LSTM(425, 64, num_layers=2, dropout=0.1, bidirectional=True)\n",
      "  (fc_dropout): Dropout(p=0.25, inplace=False)\n",
      "  (fc): Linear(in_features=128, out_features=26, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "bilstm = CharBilstm(\n",
    "    input_dim=len(dataset.word_field.vocab),\n",
    "    embedding_dim=300,\n",
    "    char_emb_dim=25,\n",
    "    char_input_dim=len(dataset.char_field.vocab),\n",
    "    char_cnn_filter_num=5,\n",
    "    char_cnn_kernel_size=3,\n",
    "    hidden_dim=64,\n",
    "    output_dim=len(dataset.tag_field.vocab),\n",
    "    lstm_layers=2,\n",
    "    emb_dropout=0.5,\n",
    "    cnn_dropout=0.25,\n",
    "    lstm_dropout=0.1,\n",
    "    fc_dropout=0.25,\n",
    "    word_pad_idx=dataset.word_pad_idx,\n",
    "    char_pad_idx=dataset.char_pad_idx\n",
    ")\n",
    "bilstm.init_embeddings(\n",
    "    char_pad_idx=dataset.char_pad_idx,\n",
    "    word_pad_idx=dataset.word_pad_idx,\n",
    "    pretrained=None,\n",
    "    freeze=True\n",
    ")\n",
    "print(f\"The model has {bilstm.count_parameters():,} trainable parameters.\")\n",
    "print(bilstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 46s\n",
      "\tTrn Loss: 1.478 | Trn Acc: 61.20%\n",
      "\tVal Loss: 1.035 | Val Acc: 69.85% | Val Precision: 60.93% | Val Recall: 41.20% | Val F1 Macro: 40.82% | Val F1 Micro: 72.08%\n",
      "Epoch: 02 | Epoch Time: 0m 49s\n",
      "\tTrn Loss: 0.781 | Trn Acc: 77.98%\n",
      "\tVal Loss: 0.657 | Val Acc: 80.98% | Val Precision: 72.17% | Val Recall: 71.71% | Val F1 Macro: 69.86% | Val F1 Micro: 81.53%\n",
      "Epoch: 03 | Epoch Time: 1m 1s\n",
      "\tTrn Loss: 0.559 | Trn Acc: 83.70%\n",
      "\tVal Loss: 0.544 | Val Acc: 83.22% | Val Precision: 68.74% | Val Recall: 63.42% | Val F1 Macro: 62.80% | Val F1 Micro: 82.53%\n",
      "Epoch: 04 | Epoch Time: 0m 58s\n",
      "\tTrn Loss: 0.472 | Trn Acc: 85.56%\n",
      "\tVal Loss: 0.543 | Val Acc: 82.79% | Val Precision: 66.66% | Val Recall: 63.03% | Val F1 Macro: 61.87% | Val F1 Micro: 81.68%\n",
      "Epoch: 05 | Epoch Time: 0m 57s\n",
      "\tTrn Loss: 0.421 | Trn Acc: 86.83%\n",
      "\tVal Loss: 0.493 | Val Acc: 84.50% | Val Precision: 69.86% | Val Recall: 63.73% | Val F1 Macro: 64.15% | Val F1 Micro: 83.20%\n",
      "Epoch: 06 | Epoch Time: 0m 56s\n",
      "\tTrn Loss: 0.386 | Trn Acc: 87.75%\n",
      "\tVal Loss: 0.482 | Val Acc: 84.57% | Val Precision: 69.80% | Val Recall: 69.27% | Val F1 Macro: 67.54% | Val F1 Micro: 83.21%\n",
      "Epoch: 07 | Epoch Time: 0m 54s\n",
      "\tTrn Loss: 0.357 | Trn Acc: 88.62%\n",
      "\tVal Loss: 0.484 | Val Acc: 84.42% | Val Precision: 71.99% | Val Recall: 68.69% | Val F1 Macro: 68.15% | Val F1 Micro: 83.13%\n",
      "Epoch: 08 | Epoch Time: 0m 50s\n",
      "\tTrn Loss: 0.330 | Trn Acc: 89.22%\n",
      "\tVal Loss: 0.467 | Val Acc: 85.22% | Val Precision: 69.79% | Val Recall: 70.82% | Val F1 Macro: 68.52% | Val F1 Micro: 83.86%\n",
      "Epoch: 09 | Epoch Time: 0m 50s\n",
      "\tTrn Loss: 0.310 | Trn Acc: 89.80%\n",
      "\tVal Loss: 0.475 | Val Acc: 85.42% | Val Precision: 72.59% | Val Recall: 72.26% | Val F1 Macro: 70.78% | Val F1 Micro: 84.07%\n",
      "Epoch: 10 | Epoch Time: 0m 51s\n",
      "\tTrn Loss: 0.295 | Trn Acc: 90.24%\n",
      "\tVal Loss: 0.474 | Val Acc: 84.97% | Val Precision: 72.49% | Val Recall: 71.67% | Val F1 Macro: 70.24% | Val F1 Micro: 83.57%\n",
      "Epoch: 11 | Epoch Time: 0m 52s\n",
      "\tTrn Loss: 0.282 | Trn Acc: 90.57%\n",
      "\tVal Loss: 0.487 | Val Acc: 85.20% | Val Precision: 74.56% | Val Recall: 70.44% | Val F1 Macro: 70.58% | Val F1 Micro: 83.81%\n",
      "Epoch: 12 | Epoch Time: 0m 50s\n",
      "\tTrn Loss: 0.266 | Trn Acc: 91.04%\n",
      "\tVal Loss: 0.481 | Val Acc: 85.50% | Val Precision: 73.00% | Val Recall: 71.26% | Val F1 Macro: 70.36% | Val F1 Micro: 84.07%\n",
      "Epoch: 13 | Epoch Time: 0m 50s\n",
      "\tTrn Loss: 0.251 | Trn Acc: 91.53%\n",
      "\tVal Loss: 0.504 | Val Acc: 84.74% | Val Precision: 70.21% | Val Recall: 72.99% | Val F1 Macro: 69.68% | Val F1 Micro: 83.29%\n",
      "Epoch: 14 | Epoch Time: 0m 53s\n",
      "\tTrn Loss: 0.240 | Trn Acc: 91.88%\n",
      "\tVal Loss: 0.493 | Val Acc: 85.41% | Val Precision: 72.46% | Val Recall: 71.01% | Val F1 Macro: 70.01% | Val F1 Micro: 83.93%\n",
      "Epoch: 15 | Epoch Time: 0m 49s\n",
      "\tTrn Loss: 0.229 | Trn Acc: 92.18%\n",
      "\tVal Loss: 0.506 | Val Acc: 85.25% | Val Precision: 71.33% | Val Recall: 69.67% | Val F1 Macro: 68.60% | Val F1 Micro: 83.75%\n",
      "Epoch: 16 | Epoch Time: 0m 58s\n",
      "\tTrn Loss: 0.215 | Trn Acc: 92.66%\n",
      "\tVal Loss: 0.543 | Val Acc: 85.41% | Val Precision: 72.59% | Val Recall: 70.85% | Val F1 Macro: 69.90% | Val F1 Micro: 83.90%\n",
      "Epoch: 17 | Epoch Time: 1m 2s\n",
      "\tTrn Loss: 0.205 | Trn Acc: 92.98%\n",
      "\tVal Loss: 0.524 | Val Acc: 85.38% | Val Precision: 72.17% | Val Recall: 71.29% | Val F1 Macro: 69.93% | Val F1 Micro: 83.90%\n",
      "Epoch: 18 | Epoch Time: 1m 1s\n",
      "\tTrn Loss: 0.196 | Trn Acc: 93.29%\n",
      "\tVal Loss: 0.540 | Val Acc: 84.95% | Val Precision: 69.26% | Val Recall: 70.04% | Val F1 Macro: 68.10% | Val F1 Micro: 83.38%\n",
      "Epoch: 19 | Epoch Time: 1m 6s\n",
      "\tTrn Loss: 0.192 | Trn Acc: 93.44%\n",
      "\tVal Loss: 0.532 | Val Acc: 85.21% | Val Precision: 70.95% | Val Recall: 71.46% | Val F1 Macro: 69.50% | Val F1 Micro: 83.69%\n",
      "Epoch: 20 | Epoch Time: 1m 1s\n",
      "\tTrn Loss: 0.180 | Trn Acc: 93.82%\n",
      "\tVal Loss: 0.552 | Val Acc: 85.22% | Val Precision: 70.10% | Val Recall: 70.88% | Val F1 Macro: 68.83% | Val F1 Micro: 83.73%\n"
     ]
    }
   ],
   "source": [
    "ner = CharBilstmTrainer(\n",
    "  model=bilstm,\n",
    "  data=dataset,\n",
    "  optimizer_cls=Adam,\n",
    "  loss_fn_cls=nn.CrossEntropyLoss,\n",
    "  log_file=\"char_bilstm_vanilla\"\n",
    ")\n",
    "ner.train(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('kpmg': conda)",
   "language": "python",
   "name": "python371064bitkpmgconda9ab805a6f13f4730b4aaa5e98639804c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
