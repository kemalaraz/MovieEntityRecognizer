{
 "cells": [
  {
   "source": [
    "## BiLSTM for MIT Movies\n",
    "I was going to make this repository a package with setup.py and everything but because of my deadlines and responsibilities at my current workplace I haven't got the time to do that so I shared the structure of the project in README.md file."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from src.movientities.models.lstm import BiLSTM\n",
    "from src.movientities.utils.processors import NerPreProcessor\n",
    "from src.movientities.trainers import TrainerBiLstm\n",
    "from src.movientities.data.build_dataset import Corpus, BuildData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets with tab as splitter for corpus of torch text to handle\n",
    "BuildData.create_finaldata(\"/home/kemalaraz/Desktop/MovieEntityRecognizer/data/raw/mitmovies/engtest.bio\", \"/home/kemalaraz/Desktop/MovieEntityRecognizer/data/modified/mitmovies_tab_format/test.txt\", splits=\"\\t\")\n",
    "BuildData.create_finaldata(\"/home/kemalaraz/Desktop/MovieEntityRecognizer/data/raw/mitmovies/engtest.bio\", \"/home/kemalaraz/Desktop/MovieEntityRecognizer/data/modified/mitmovies_tab_format/test.txt\", splits=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 9775 sentences\n",
      "Test set: 2443 sentences\n"
     ]
    }
   ],
   "source": [
    "dataset = Corpus(\n",
    "    input_folder=\"/home/kemalaraz/Desktop/MovieEntityRecognizer/data/modified/mitmovies_tab_format\",\n",
    "    min_word_freq=3,  # any words occurring less than 3 times will be ignored from vocab\n",
    "    batch_size=64)\n",
    "print(f\"Train set: {len(dataset.train_dataset)} sentences\")\n",
    "print(f\"Test set: {len(dataset.test_dataset)} sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 1,161,930 trainable parameters.\n",
      "BiLSTM(\n",
      "  (embedding): Embedding(2244, 300, padding_idx=1)\n",
      "  (emb_dropout): Dropout(p=0.25, inplace=False)\n",
      "  (lstm): LSTM(300, 64, num_layers=4, dropout=0.01, bidirectional=True)\n",
      "  (fc_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (fc): Linear(in_features=128, out_features=26, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = BiLSTM(\n",
    "    input_dim=len(dataset.word_field.vocab),\n",
    "    embedding_dim=300,\n",
    "    hidden_dim=64,\n",
    "    output_dim=len(dataset.tag_field.vocab),\n",
    "    lstm_layers=4,\n",
    "    emb_dropout=0.25,\n",
    "    lstm_dropout=0.01,\n",
    "    fc_dropout=0.1,\n",
    "    word_pad_idx=dataset.word_pad_idx,\n",
    ")\n",
    "# Initialize weights and embeddings\n",
    "model.init_weights()\n",
    "model.init_embeddings(word_pad_idx=dataset.word_pad_idx)\n",
    "print(f\"The model has {model.count_parameters():,} trainable parameters.\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 22s\n",
      "\tTrn Loss: 0.903 | Trn Acc: 75.58%\n",
      "\tVal Loss: 0.763 | Val Acc: 80.36% | Val Precision: 60.83% | Val Recall: 55.18% | Val F1 Macro: 53.84% | Val F1 Micro: 80.28%\n",
      "Epoch: 02 | Epoch Time: 0m 22s\n",
      "\tTrn Loss: 0.448 | Trn Acc: 88.92%\n",
      "\tVal Loss: 0.520 | Val Acc: 87.07% | Val Precision: 74.27% | Val Recall: 72.57% | Val F1 Macro: 70.96% | Val F1 Micro: 86.40%\n",
      "Epoch: 03 | Epoch Time: 0m 22s\n",
      "\tTrn Loss: 0.321 | Trn Acc: 92.06%\n",
      "\tVal Loss: 0.453 | Val Acc: 88.60% | Val Precision: 75.65% | Val Recall: 75.65% | Val F1 Macro: 73.28% | Val F1 Micro: 87.79%\n",
      "Epoch: 04 | Epoch Time: 0m 21s\n",
      "\tTrn Loss: 0.272 | Trn Acc: 93.18%\n",
      "\tVal Loss: 0.432 | Val Acc: 88.86% | Val Precision: 77.34% | Val Recall: 73.99% | Val F1 Macro: 73.20% | Val F1 Micro: 87.94%\n",
      "Epoch: 05 | Epoch Time: 0m 22s\n",
      "\tTrn Loss: 0.238 | Trn Acc: 94.04%\n",
      "\tVal Loss: 0.415 | Val Acc: 89.34% | Val Precision: 74.38% | Val Recall: 74.84% | Val F1 Macro: 72.41% | Val F1 Micro: 88.23%\n",
      "Epoch: 06 | Epoch Time: 0m 21s\n",
      "\tTrn Loss: 0.210 | Trn Acc: 94.56%\n",
      "\tVal Loss: 0.401 | Val Acc: 89.78% | Val Precision: 75.28% | Val Recall: 76.24% | Val F1 Macro: 73.80% | Val F1 Micro: 88.64%\n",
      "Epoch: 07 | Epoch Time: 0m 21s\n",
      "\tTrn Loss: 0.190 | Trn Acc: 95.08%\n",
      "\tVal Loss: 0.394 | Val Acc: 90.34% | Val Precision: 81.01% | Val Recall: 78.57% | Val F1 Macro: 77.77% | Val F1 Micro: 89.26%\n",
      "Epoch: 08 | Epoch Time: 0m 21s\n",
      "\tTrn Loss: 0.174 | Trn Acc: 95.43%\n",
      "\tVal Loss: 0.377 | Val Acc: 90.75% | Val Precision: 79.25% | Val Recall: 78.46% | Val F1 Macro: 77.28% | Val F1 Micro: 89.65%\n",
      "Epoch: 09 | Epoch Time: 0m 21s\n",
      "\tTrn Loss: 0.155 | Trn Acc: 95.88%\n",
      "\tVal Loss: 0.400 | Val Acc: 90.46% | Val Precision: 78.56% | Val Recall: 76.90% | Val F1 Macro: 76.16% | Val F1 Micro: 89.35%\n",
      "Epoch: 10 | Epoch Time: 0m 22s\n",
      "\tTrn Loss: 0.143 | Trn Acc: 96.10%\n",
      "\tVal Loss: 0.423 | Val Acc: 90.14% | Val Precision: 76.37% | Val Recall: 77.53% | Val F1 Macro: 75.20% | Val F1 Micro: 89.04%\n",
      "Epoch: 11 | Epoch Time: 0m 22s\n",
      "\tTrn Loss: 0.134 | Trn Acc: 96.35%\n",
      "\tVal Loss: 0.397 | Val Acc: 90.61% | Val Precision: 78.11% | Val Recall: 78.22% | Val F1 Macro: 76.48% | Val F1 Micro: 89.48%\n",
      "Epoch: 12 | Epoch Time: 0m 23s\n",
      "\tTrn Loss: 0.121 | Trn Acc: 96.70%\n",
      "\tVal Loss: 0.395 | Val Acc: 90.74% | Val Precision: 78.15% | Val Recall: 77.47% | Val F1 Macro: 76.08% | Val F1 Micro: 89.54%\n",
      "Epoch: 13 | Epoch Time: 0m 23s\n",
      "\tTrn Loss: 0.111 | Trn Acc: 96.94%\n",
      "\tVal Loss: 0.430 | Val Acc: 90.54% | Val Precision: 78.11% | Val Recall: 77.00% | Val F1 Macro: 75.97% | Val F1 Micro: 89.39%\n",
      "Epoch: 14 | Epoch Time: 0m 23s\n",
      "\tTrn Loss: 0.102 | Trn Acc: 97.15%\n",
      "\tVal Loss: 0.401 | Val Acc: 90.83% | Val Precision: 75.97% | Val Recall: 76.71% | Val F1 Macro: 74.92% | Val F1 Micro: 89.56%\n",
      "Epoch: 15 | Epoch Time: 0m 24s\n",
      "\tTrn Loss: 0.094 | Trn Acc: 97.32%\n",
      "\tVal Loss: 0.409 | Val Acc: 91.04% | Val Precision: 78.06% | Val Recall: 77.96% | Val F1 Macro: 76.53% | Val F1 Micro: 89.87%\n",
      "Epoch: 16 | Epoch Time: 0m 24s\n",
      "\tTrn Loss: 0.087 | Trn Acc: 97.55%\n",
      "\tVal Loss: 0.423 | Val Acc: 90.80% | Val Precision: 79.64% | Val Recall: 76.99% | Val F1 Macro: 76.63% | Val F1 Micro: 89.62%\n",
      "Epoch: 17 | Epoch Time: 0m 23s\n",
      "\tTrn Loss: 0.081 | Trn Acc: 97.65%\n",
      "\tVal Loss: 0.427 | Val Acc: 90.82% | Val Precision: 79.41% | Val Recall: 77.24% | Val F1 Macro: 76.55% | Val F1 Micro: 89.63%\n",
      "Epoch: 18 | Epoch Time: 0m 24s\n",
      "\tTrn Loss: 0.073 | Trn Acc: 97.85%\n",
      "\tVal Loss: 0.442 | Val Acc: 90.83% | Val Precision: 78.28% | Val Recall: 78.13% | Val F1 Macro: 76.66% | Val F1 Micro: 89.64%\n",
      "Epoch: 19 | Epoch Time: 0m 23s\n",
      "\tTrn Loss: 0.067 | Trn Acc: 97.98%\n",
      "\tVal Loss: 0.445 | Val Acc: 91.00% | Val Precision: 78.04% | Val Recall: 78.45% | Val F1 Macro: 76.45% | Val F1 Micro: 89.81%\n",
      "Epoch: 20 | Epoch Time: 0m 24s\n",
      "\tTrn Loss: 0.063 | Trn Acc: 98.14%\n",
      "\tVal Loss: 0.453 | Val Acc: 91.21% | Val Precision: 78.82% | Val Recall: 78.45% | Val F1 Macro: 76.99% | Val F1 Micro: 90.01%\n"
     ]
    }
   ],
   "source": [
    "ner = TrainerBiLstm(\n",
    "  model=model,\n",
    "  data=dataset,\n",
    "  optimizer_cls=Adam,\n",
    "  loss_fn_cls=nn.CrossEntropyLoss,\n",
    "  log_name=\"bilstm_vanilla2\"\n",
    ")\n",
    "ner.train(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20 Epoch Adam lr 0.001lstm drop 0.1 fc dopr 0.25 batch 64\n",
    "\n",
    "Epoch: 01 | Epoch Time: 0m 29s\n",
    "\tTrn Loss: 1.658 | Trn Acc: 61.69%\n",
    "\tVal Loss: 1.227 | Val Acc: 66.63% | Val Precision: 31.96% | Val Recall: 52.00% | Val F1 Macro: 36.41% | Val F1 Micro: 72.99%\n",
    "Epoch: 02 | Epoch Time: 0m 34s\n",
    "\tTrn Loss: 0.845 | Trn Acc: 76.78%\n",
    "\tVal Loss: 0.753 | Val Acc: 80.34% | Val Precision: 57.47% | Val Recall: 55.16% | Val F1 Macro: 52.33% | Val F1 Micro: 80.03%\n",
    "Epoch: 03 | Epoch Time: 0m 33s\n",
    "\tTrn Loss: 0.538 | Trn Acc: 86.26%\n",
    "\tVal Loss: 0.600 | Val Acc: 85.45% | Val Precision: 70.97% | Val Recall: 69.60% | Val F1 Macro: 67.31% | Val F1 Micro: 84.88%\n",
    "Epoch: 04 | Epoch Time: 0m 33s\n",
    "\tTrn Loss: 0.412 | Trn Acc: 89.78%\n",
    "\tVal Loss: 0.476 | Val Acc: 88.51% | Val Precision: 73.39% | Val Recall: 75.89% | Val F1 Macro: 72.66% | Val F1 Micro: 87.82%\n",
    "Epoch: 05 | Epoch Time: 0m 34s\n",
    "\tTrn Loss: 0.346 | Trn Acc: 91.46%\n",
    "\tVal Loss: 0.458 | Val Acc: 88.67% | Val Precision: 73.57% | Val Recall: 73.83% | Val F1 Macro: 71.65% | Val F1 Micro: 87.77%\n",
    "Epoch: 06 | Epoch Time: 0m 33s\n",
    "\tTrn Loss: 0.305 | Trn Acc: 92.39%\n",
    "\tVal Loss: 0.432 | Val Acc: 89.27% | Val Precision: 76.20% | Val Recall: 74.37% | Val F1 Macro: 73.06% | Val F1 Micro: 88.32%\n",
    "Epoch: 07 | Epoch Time: 0m 25s\n",
    "\tTrn Loss: 0.275 | Trn Acc: 93.19%\n",
    "\tVal Loss: 0.435 | Val Acc: 89.10% | Val Precision: 77.82% | Val Recall: 75.45% | Val F1 Macro: 74.63% | Val F1 Micro: 88.10%\n",
    "Epoch: 08 | Epoch Time: 0m 29s\n",
    "\tTrn Loss: 0.256 | Trn Acc: 93.59%\n",
    "\tVal Loss: 0.432 | Val Acc: 89.23% | Val Precision: 77.96% | Val Recall: 75.78% | Val F1 Macro: 74.90% | Val F1 Micro: 88.20%\n",
    "Epoch: 09 | Epoch Time: 0m 31s\n",
    "\tTrn Loss: 0.233 | Trn Acc: 94.13%\n",
    "\tVal Loss: 0.407 | Val Acc: 90.06% | Val Precision: 78.80% | Val Recall: 77.47% | Val F1 Macro: 76.32% | Val F1 Micro: 88.94%\n",
    "Epoch: 10 | Epoch Time: 0m 27s\n",
    "\tTrn Loss: 0.217 | Trn Acc: 94.55%\n",
    "\tVal Loss: 0.394 | Val Acc: 90.39% | Val Precision: 80.00% | Val Recall: 79.13% | Val F1 Macro: 77.82% | Val F1 Micro: 89.33%\n",
    "Epoch: 11 | Epoch Time: 0m 25s\n",
    "\tTrn Loss: 0.205 | Trn Acc: 94.79%\n",
    "\tVal Loss: 0.396 | Val Acc: 90.41% | Val Precision: 78.76% | Val Recall: 77.90% | Val F1 Macro: 76.47% | Val F1 Micro: 89.24%\n",
    "Epoch: 12 | Epoch Time: 0m 24s\n",
    "\tTrn Loss: 0.191 | Trn Acc: 95.05%\n",
    "\tVal Loss: 0.428 | Val Acc: 89.46% | Val Precision: 77.10% | Val Recall: 76.90% | Val F1 Macro: 74.92% | Val F1 Micro: 88.31%\n",
    "Epoch: 13 | Epoch Time: 0m 25s\n",
    "\tTrn Loss: 0.179 | Trn Acc: 95.34%\n",
    "\tVal Loss: 0.392 | Val Acc: 90.74% | Val Precision: 80.24% | Val Recall: 79.21% | Val F1 Macro: 78.04% | Val F1 Micro: 89.60%\n",
    "Epoch: 14 | Epoch Time: 0m 26s\n",
    "\tTrn Loss: 0.170 | Trn Acc: 95.51%\n",
    "\tVal Loss: 0.419 | Val Acc: 90.37% | Val Precision: 79.34% | Val Recall: 79.72% | Val F1 Macro: 77.80% | Val F1 Micro: 89.25%\n",
    "Epoch: 15 | Epoch Time: 0m 24s\n",
    "\tTrn Loss: 0.164 | Trn Acc: 95.68%\n",
    "\tVal Loss: 0.392 | Val Acc: 90.65% | Val Precision: 79.81% | Val Recall: 79.83% | Val F1 Macro: 78.28% | Val F1 Micro: 89.53%\n",
    "Epoch: 16 | Epoch Time: 0m 26s\n",
    "\tTrn Loss: 0.154 | Trn Acc: 95.89%\n",
    "\tVal Loss: 0.404 | Val Acc: 90.56% | Val Precision: 79.85% | Val Recall: 78.63% | Val F1 Macro: 77.54% | Val F1 Micro: 89.40%\n",
    "Epoch: 17 | Epoch Time: 0m 26s\n",
    "\tTrn Loss: 0.148 | Trn Acc: 95.99%\n",
    "\tVal Loss: 0.400 | Val Acc: 90.59% | Val Precision: 78.39% | Val Recall: 77.84% | Val F1 Macro: 76.49% | Val F1 Micro: 89.40%\n",
    "Epoch: 18 | Epoch Time: 0m 28s\n",
    "\tTrn Loss: 0.140 | Trn Acc: 96.25%\n",
    "\tVal Loss: 0.434 | Val Acc: 90.37% | Val Precision: 79.29% | Val Recall: 78.36% | Val F1 Macro: 77.08% | Val F1 Micro: 89.21%\n",
    "Epoch: 19 | Epoch Time: 0m 29s\n",
    "\tTrn Loss: 0.135 | Trn Acc: 96.33%\n",
    "\tVal Loss: 0.402 | Val Acc: 91.19% | Val Precision: 80.33% | Val Recall: 78.81% | Val F1 Macro: 77.74% | Val F1 Micro: 89.98%\n",
    "Epoch: 20 | Epoch Time: 0m 24s\n",
    "\tTrn Loss: 0.126 | Trn Acc: 96.57%\n",
    "\tVal Loss: 0.381 | Val Acc: 91.04% | Val Precision: 78.34% | Val Recall: 77.63% | Val F1 Macro: 76.52% | Val F1 Micro: 89.79%\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('project': conda)",
   "metadata": {
    "interpreter": {
     "hash": "14dbe4d4df743aee721c7bd8dbc75325a1aee7c29f250bc6dc30066efadd3ddb"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}