{
 "cells": [
  {
   "source": [
    "## Char BiLSTM for MIT Movies\n",
    "I was going to make this repository a package with setup.py and everything but because of my deadlines and responsibilities at my current workplace I haven't got the time to do that so I shared the structure of the project in README.md file."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from src.namedentityrecognizer.trainers import CharBilstmTrainer\n",
    "from src.namedentityrecognizer.models.char_lstm import CharBilstm\n",
    "from src.namedentityrecognizer.utils.processors import NerPreProcessor\n",
    "from src.namedentityrecognizer.data.build_dataset import CharCorpus, BuildData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/home/karaz/Desktop/NamedEntityRecognizer\n"
     ]
    }
   ],
   "source": [
    "# For finding the absolute path dynamically for every other user for the sake of this notebooks paths\n",
    "for path in globals()['_dh']:\n",
    "    if \"NamedEntityRecognizer\" in path.split(os.sep):\n",
    "        absolute_path = path\n",
    "        break\n",
    "print(absolute_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train set: 9775 sentences\nTest set: 2443 sentences\n"
     ]
    }
   ],
   "source": [
    "dataset = CharCorpus(\n",
    "    input_folder=os.path.join(absolute_path, \"data/modified/mitmovies_tab_format\"),\n",
    "    min_word_freq=3,\n",
    "    batch_size=64,\n",
    ")\n",
    "print(f\"Train set: {len(dataset.train_dataset)} sentences\")\n",
    "print(f\"Test set: {len(dataset.test_dataset)} sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets with tab as splitter for corpus of torch text to handle - Uncomment if needed -\n",
    "# Convert ->  O\tgood             -> to ->  good     O           \n",
    "# Convert ->  B-GENRE\tromantic -> to ->  romantic B-GENRE\n",
    "# Convert ->  I-GENRE\tcomedies -> to ->  comedies I-GENRE\n",
    "BuildData.create_finaldata(os.path.join(absolute_path, \"data/raw/mitmovies/engtrain.bio\"), os.path.join(absolute_path, \"data/modified/mitmovies_tab_format/train.txt\"), splits=\"\\t\")\n",
    "BuildData.create_finaldata(os.path.join(absolute_path, \"data/raw/mitmovies/engtest.bio\"), os.path.join(absolute_path, \"data/modified/mitmovies_tab_format/test.txt\"), splits=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The model has 1,028,749 trainable parameters.\nCharBilstm(\n  (embedding): Embedding(2244, 300, padding_idx=1)\n  (emb_dropout): Dropout(p=0.5, inplace=False)\n  (char_emb): Embedding(39, 25, padding_idx=1)\n  (char_cnn): Conv1d(25, 125, kernel_size=(3,), stride=(1,), groups=25)\n  (cnn_dropout): Dropout(p=0.25, inplace=False)\n  (lstm): LSTM(425, 64, num_layers=2, dropout=0.1, bidirectional=True)\n  (fc_dropout): Dropout(p=0.25, inplace=False)\n  (fc): Linear(in_features=128, out_features=26, bias=True)\n)\n"
     ]
    }
   ],
   "source": [
    "bilstm = CharBilstm(\n",
    "    input_dim=len(dataset.word_field.vocab),\n",
    "    embedding_dim=300,\n",
    "    char_emb_dim=25,\n",
    "    char_input_dim=len(dataset.char_field.vocab),\n",
    "    char_cnn_filter_num=5,\n",
    "    char_cnn_kernel_size=3,\n",
    "    hidden_dim=64,\n",
    "    output_dim=len(dataset.tag_field.vocab),\n",
    "    lstm_layers=2,\n",
    "    emb_dropout=0.5,\n",
    "    cnn_dropout=0.25,\n",
    "    lstm_dropout=0.1,\n",
    "    fc_dropout=0.25,\n",
    "    word_pad_idx=dataset.word_pad_idx,\n",
    "    char_pad_idx=dataset.char_pad_idx\n",
    ")\n",
    "bilstm.init_embeddings(\n",
    "    char_pad_idx=dataset.char_pad_idx,\n",
    "    word_pad_idx=dataset.word_pad_idx,\n",
    "    pretrained=None,\n",
    "    freeze=True\n",
    ")\n",
    "print(f\"The model has {bilstm.count_parameters():,} trainable parameters.\")\n",
    "print(bilstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 23s\n",
      "\tTrn Loss: 1.444 | Trn Acc: 66.13%\n",
      "\tVal Loss: 0.790 | Val Acc: 80.55% | Val Precision: 58.77% | Val Recall: 59.20% | Val F1 Macro: 54.81% | Val F1 Micro: 80.60%\n",
      "Epoch: 02 | Epoch Time: 0m 23s\n",
      "\tTrn Loss: 0.513 | Trn Acc: 87.15%\n",
      "\tVal Loss: 0.489 | Val Acc: 87.67% | Val Precision: 73.82% | Val Recall: 76.50% | Val F1 Macro: 72.22% | Val F1 Micro: 87.06%\n",
      "Epoch: 03 | Epoch Time: 0m 23s\n",
      "\tTrn Loss: 0.362 | Trn Acc: 90.74%\n",
      "\tVal Loss: 0.427 | Val Acc: 89.18% | Val Precision: 76.67% | Val Recall: 78.20% | Val F1 Macro: 74.04% | Val F1 Micro: 88.27%\n",
      "Epoch: 04 | Epoch Time: 0m 23s\n",
      "\tTrn Loss: 0.301 | Trn Acc: 92.31%\n",
      "\tVal Loss: 0.392 | Val Acc: 89.93% | Val Precision: 78.82% | Val Recall: 79.45% | Val F1 Macro: 76.17% | Val F1 Micro: 88.96%\n",
      "Epoch: 05 | Epoch Time: 0m 23s\n",
      "\tTrn Loss: 0.265 | Trn Acc: 93.18%\n",
      "\tVal Loss: 0.387 | Val Acc: 90.22% | Val Precision: 78.56% | Val Recall: 79.71% | Val F1 Macro: 75.83% | Val F1 Micro: 89.11%\n"
     ]
    }
   ],
   "source": [
    "ner = CharBilstmTrainer(\n",
    "  model=bilstm,\n",
    "  data=dataset,\n",
    "  optimizer_cls=Adam,\n",
    "  loss_fn_cls=nn.CrossEntropyLoss,\n",
    "  log_file=\"char_bilstm_vanilla\"\n",
    ")\n",
    "ner.train(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "word    \tunk     \tpred tag\n4       \t        \tO      \nstar    \t        \tO      \nmovies  \t        \tO      \nthat    \t        \tO      \nNicholas\t        \tB-ACTOR\nCage    \t        \tI-ACTOR\nis      \t        \tO      \nplaying \t        \tO      \n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(['4', 'star', 'movies', 'that', 'Nicholas', 'Cage', 'is', 'playing'],\n",
       " ['O', 'O', 'O', 'O', 'B-ACTOR', 'I-ACTOR', 'O', 'O'],\n",
       " [])"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "ner.infer(\"4 star movies that Nicholas Cage is playing\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('project': conda)",
   "metadata": {
    "interpreter": {
     "hash": "14dbe4d4df743aee721c7bd8dbc75325a1aee7c29f250bc6dc30066efadd3ddb"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}